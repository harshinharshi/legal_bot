{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\projects\\legal_bot\\venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: pymupdf in c:\\projects\\legal_bot\\venv\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\projects\\legal_bot\\venv\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: tiktoken in c:\\projects\\legal_bot\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: langchain in c:\\projects\\legal_bot\\venv\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from faiss-cpu) (2.2.2)\n",
      "Requirement already satisfied: packaging in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (4.48.1)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: filelock in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\projects\\legal_bot\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu pymupdf sentence-transformers tiktoken langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Revenue. \n",
      "26. The appellant Trust, aggrieved by the judgment delivered by the single \n",
      "judge, filed an appeal in D.B. Special Appeal Writ No. 20/2012. The division \n",
      "bench of the High Court in its order dated 01.12.2014 observed that the \n",
      "appellant Trust had only reiterated the submissions made before the single \n",
      "judge. The said submissions were considered at length by the single judge \n",
      "and therefore, did not warrant any interference from the division bench.\n",
      "\n",
      "Result 2:\n",
      "Page 5 of 57 \n",
      " \n",
      "12. In the meantime, the Registrar, Board of Revenue, Ajmer sent a letter dated \n",
      "22.03.1980 to the appellant Trust apprising them of the ongoing litigation \n",
      "before the Revenue Appellate Authority with respect to the land bearing \n",
      "Survey no. 229 and instructed the appellant Trust not to deposit the \n",
      "compensation amount till the final decision of the appeal.  \n",
      "13. According to the appellant Trust, the memo of handing over of the\n",
      "\n",
      "Result 3:\n",
      "instead fall within the amplitude of Entry 11-A, List III.  \n",
      " \n",
      "14. \n",
      "At this juncture, let us address the argument of the appellant that \n",
      "differentiation in the refund of fees applicable between the Central and \n",
      "State legislation would defeat the overall, salutary purpose of Section \n",
      "89 CPC.   \n",
      "14.1  \n",
      "Reference may be made to the High Court of Judicature at \n",
      "Madras v. M.C. Subramaniam23, wherein it has been held that the \n",
      "provision must be understood in the “backdrop of the long-standing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF for PDF reading\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Path to folder containing judgments\n",
    "JUDGMENT_FOLDER = r\"C:\\projects\\legal_bot\\judgements\"\n",
    "\n",
    "# Load embedding model (free Hugging Face model)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "# Load all PDFs from the folder\n",
    "pdf_files = [os.path.join(JUDGMENT_FOLDER, f) for f in os.listdir(JUDGMENT_FOLDER) if f.endswith(\".pdf\")]\n",
    "documents = [extract_text_from_pdf(pdf) for pdf in pdf_files]\n",
    "\n",
    "# Split text into chunks for better embedding\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = [chunk for doc in documents for chunk in text_splitter.split_text(doc)]\n",
    "\n",
    "# Generate embeddings and store in FAISS\n",
    "vector_store = FAISS.from_texts(chunks, embedding_model)\n",
    "\n",
    "# Save FAISS index\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# Load FAISS index for querying\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Function to perform a query\n",
    "def query_rag(query):\n",
    "    docs = vector_store.similarity_search(query, k=3)  # Retrieve top 3 relevant documents\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "# Example query\n",
    "query = \"What was the judgment on corporate tax evasion?\"\n",
    "results = query_rag(query)\n",
    "\n",
    "# Print retrieved chunks\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\\n{res}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1 (From: 3369_2010_15_1502_58012_Judgement_13-Dec-2024.pdf):\n",
      "Revenue. \n",
      "26. The appellant Trust, aggrieved by the judgment delivered by the single \n",
      "judge, filed an appeal in D.B. Special Appeal Writ No. 20/2012. The division \n",
      "bench of the High Court in its order dated 01.12.2014 observed that the \n",
      "appellant Trust had only reiterated the submissions made before the single \n",
      "judge. The said submissions were considered at length by the single judge \n",
      "and therefore, did not warrant any interference from the division bench.\n",
      "\n",
      "Result 2 (From: 3369_2010_15_1502_58012_Judgement_13-Dec-2024.pdf):\n",
      "Page 5 of 57 \n",
      " \n",
      "12. In the meantime, the Registrar, Board of Revenue, Ajmer sent a letter dated \n",
      "22.03.1980 to the appellant Trust apprising them of the ongoing litigation \n",
      "before the Revenue Appellate Authority with respect to the land bearing \n",
      "Survey no. 229 and instructed the appellant Trust not to deposit the \n",
      "compensation amount till the final decision of the appeal.  \n",
      "13. According to the appellant Trust, the memo of handing over of the\n",
      "\n",
      "Result 3 (From: 881_2015_9_1507_58088_Judgement_19-Dec-2024.pdf):\n",
      "instead fall within the amplitude of Entry 11-A, List III.  \n",
      " \n",
      "14. \n",
      "At this juncture, let us address the argument of the appellant that \n",
      "differentiation in the refund of fees applicable between the Central and \n",
      "State legislation would defeat the overall, salutary purpose of Section \n",
      "89 CPC.   \n",
      "14.1  \n",
      "Reference may be made to the High Court of Judicature at \n",
      "Madras v. M.C. Subramaniam23, wherein it has been held that the \n",
      "provision must be understood in the “backdrop of the long-standing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF for PDF reading\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Path to folder containing judgments\n",
    "JUDGMENT_FOLDER = r\"C:\\projects\\legal_bot\\judgements\"\n",
    "\n",
    "\n",
    "# Load embedding model (free Hugging Face model)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "# Load all PDFs from the folder\n",
    "pdf_files = [os.path.join(JUDGMENT_FOLDER, f) for f in os.listdir(JUDGMENT_FOLDER) if f.endswith(\".pdf\")]\n",
    "\n",
    "# Store document chunks with metadata (filename)\n",
    "documents = []\n",
    "for pdf_path in pdf_files:\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    file_name = os.path.basename(pdf_path)  # Extract only filename\n",
    "\n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    # Store chunks as LangChain Document objects with metadata\n",
    "    for chunk in chunks:\n",
    "        documents.append(Document(page_content=chunk, metadata={\"source\": file_name}))\n",
    "\n",
    "# Generate embeddings and store in FAISS\n",
    "vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# Save FAISS index\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# Load FAISS index for querying\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Function to perform a query and return text with source PDF file name\n",
    "def query_rag(query):\n",
    "    docs = vector_store.similarity_search(query, k=3)  # Retrieve top 3 relevant chunks\n",
    "    return [(doc.page_content, doc.metadata[\"source\"]) for doc in docs]\n",
    "\n",
    "# Example query\n",
    "query = \"What was the judgment on corporate tax evasion?\"\n",
    "results = query_rag(query)\n",
    "\n",
    "# Print retrieved results with file names\n",
    "for i, (text, source) in enumerate(results):\n",
    "    print(f\"\\nResult {i+1} (From: {source}):\\n{text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
